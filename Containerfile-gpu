# Image with GPU CUDA only backend.
FROM nvcr.io/nvidia/cuda:12.9.1-devel-ubi9

# Install Python
RUN dnf install -y --nodocs --setopt=keepcache=0 --setopt=tsflags=nodocs \
    python3.12 python3.12-devel python3.12-pip libcudnn9 libnccl libcusparselt0 && \
    dnf clean all
RUN ln -sf /usr/bin/python3.12 /usr/bin/python
ENV LD_LIBRARY_PATH=/usr/local/cuda-12/compat:$LD_LIBRARY_PATH

# Install asciidoctor
RUN dnf install -y rubygems && \
    dnf clean all && \
    gem install asciidoctor
# Install uv package manager
RUN pip3.12 install uv==0.7.20

WORKDIR /rag-content

COPY Makefile pyproject.toml uv.lock README.md ./
COPY src ./src
COPY tests ./tests
COPY scripts ./scripts

# Configure UV environment variables for optimal performance
# Pytorch backend - cpu. `uv` contains convenient way to specify the backend.
ENV UV_COMPILE_BYTECODE=0 \
    UV_PYTHON_DOWNLOADS=0

# Remove pytorch-cpu dependency from pyproject.toml
RUN uv venv && uv pip install tomlkit
RUN uv run python ./scripts/remove_pytorch_cpu_pyproject.py

# Update uv.lock file and install dependencies
RUN uv lock && uv sync --locked --no-install-project

# Then, add the rest of the project source code and install it
# Installing separately from its dependencies allows optimal layer caching
RUN uv sync --locked

# Test PyTorch was installed with default GPU linux backend (CUDA)
#RUN uv run python -c "import torch; print(torch.__version__); assert 'cpu' not in torch.__version__;"

# Add executables from .venv to system PATH
ENV PATH="/rag-content/.venv/bin:$PATH"

# Download embeddings model
ENV EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
RUN python ./scripts/download_embeddings_model.py \
       -l ./embeddings_model \
       -r ${EMBEDDING_MODEL}

# Reset the entrypoint.
ENTRYPOINT []

LABEL description="Contains embedding model and dependencies needed to generate a vector database"
