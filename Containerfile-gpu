# Image with GPU CUDA only backend.
FROM nvcr.io/nvidia/cuda:12.8.1-devel-ubi9

# Install Python
RUN dnf install -y --nodocs --setopt=keepcache=0 --setopt=tsflags=nodocs \
    python3.12 python3.12-devel python3.12-pip && \
    dnf clean all
RUN ln -sf /usr/bin/python3.12 /usr/bin/python
ENV LD_LIBRARY_PATH=/usr/local/cuda-12.8/compat:$LD_LIBRARY_PATH

# Install asciidoctor
RUN dnf install -y rubygems && \
    dnf clean all && \
    gem install asciidoctor
# Install uv package manager
RUN pip3.12 install uv==0.7.20

WORKDIR /rag-content

COPY Makefile pyproject.toml uv.lock README.md ./
COPY src ./src
COPY tests ./tests
COPY scripts ./scripts

# Configure UV environment variables for optimal performance
# Pytorch backend - cpu. `uv` contains convenient way to specify the backend.
ENV UV_COMPILE_BYTECODE=0 \
    UV_PYTHON_DOWNLOADS=0

# Install Python dependencies
RUN uv sync --locked --no-install-project

# Then, add the rest of the project source code and install it
# Installing separately from its dependencies allows optimal layer caching
RUN uv sync --locked

# Override PyTorch installation - install CUDA variant
RUN uv pip install --upgrade torch --torch-backend=cu128

# Test PyTorch was installed with CUDA backend
RUN uv run python -c "import torch; print(torch.__version__); assert 'cu128' in torch.__version__;"

# Add executables from .venv to system PATH
ENV PATH="/rag-content/.venv/bin:$PATH"

# Download embeddings model
ENV EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
RUN python ./scripts/download_embeddings_model.py \
       -l ./embeddings_model \
       -r ${EMBEDDING_MODEL}

# Reset the entrypoint.
ENTRYPOINT []

LABEL description="Contains embedding model and dependencies needed to generate a vector database"
